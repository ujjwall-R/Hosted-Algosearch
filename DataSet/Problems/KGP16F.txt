

Competitive Programmers love concise statements. Today, we have one such problem for you!


You're given an array A with N integers, A1, A2, A3....AN. You have to partition the elements of array A into exactly K disjoint subsets such that the following conditions are satisfied:

Size of each subset must be at least 2.
Let the K subsets be S1, S2.... SK. 
Let Di = max(Si) - min(Si) where max(Si) is maximum element in Si and min(Si) is the minimum element in Si. We want to minimize value of D1 + D2 + D3 + .... + DK.



Find the minimum possible sum of D1 + D2 + D3 + .... + DK that you can obtain.

Input
The first line of the input contains an integer T denoting the number of the test cases.
The first line of each test case will contain two space separated integers N, K.
The next line will contain N space separated integers A1, A2, A3....AN 
Output
For each test case, output a single integer denoting the minimum sum.
Constraints

1 ≤ T  ≤ 10
2 ≤ N  ≤ 105
2 ≤ Sum of N over all test cases in a single file ≤ 105
1 ≤ K  ≤ min(500, N / 2)
1 ≤ Ai  ≤ 1012

Example
Input:
1
5 2
19 16 5 23 17

Output:
16

Explanation

The best partition that we can obtain involves partitioning A into {16, 5, 17} and {19, 23}, incurring a cost of (17 - 5) + (23 - 19) = 16




Author:
admin3


Tags:

               
                 acm16, admin3, dynamic-programming, icpc2016, kgp16, programming
                 
               
             
             



                        Difficulty Rating:
                    

N/A


Date Added:
15-12-2016


Time Limit:
1 secs


Source Limit:
50000 Bytes


Languages:
PYTH 3.6, JAVA, C, CPP14, PYTH, PYP3





Submit

